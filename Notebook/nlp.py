# -*- coding: utf-8 -*-
"""nlp

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1sWuQcOeUOaxoYm3F8eEZjTTG0brRRLjj
"""

import re
import string
import nltk
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize
from nltk.stem import WordNetLemmatizer

nltk.download('punkt')
nltk.download('wordnet')
nltk.download('stopwords')
import pandas as pd
from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score
import numpy as np
import tensorflow as tf
from tensorflow.keras.optimizers import RMSprop, SGD
from tensorflow.keras.preprocessing.sequence import pad_sequences
from sklearn.metrics import accuracy_score
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Embedding, SpatialDropout1D
from tensorflow.keras.preprocessing.sequence import pad_sequences
from sklearn.metrics import accuracy_score

!pip install datasets

#from datasets import load_dataset

#train_ds, val_ds, test_ds = load_dataset(
    #'allocine',
    #split=['train', 'validation', 'test']
#)

from datasets import load_dataset
# Charger le jeu de données
train_ds, val_ds, test_ds = load_dataset('allocine', split=['train', 'validation', 'test'])
# Convertir le jeu de données d'entraînement en DataFrame pandas
train_df = train_ds.to_pandas()
# Afficher les premières lignes du DataFrame
print(train_df.head())

train_df

def preprocess_text(text):
    # Convertir le texte en minuscules
    text = text.lower()

    # Supprimer la ponctuation
    text = text.translate(str.maketrans('', '', string.punctuation))

    # Supprimer les chiffres
    text = re.sub(r'\d+', '', text)

    # Tokenization
    tokens = word_tokenize(text)

    # Supprimer les stopwords
    stop_words = set(stopwords.words('french'))
    filtered_tokens = [word for word in tokens if word not in stop_words]

    # Lemmatisation
    lemmatizer = WordNetLemmatizer()
    lemmatized_tokens = [lemmatizer.lemmatize(word) for word in filtered_tokens]

    # Rejoindre les tokens pour former du texte prétraité
    preprocessed_text = ' '.join(lemmatized_tokens)

    return preprocessed_text

# Charger les données
train_ds, val_ds, test_ds = load_dataset('allocine', split=['train', 'validation', 'test'])

# Prétraiter chaque texte dans l'ensemble de données d'entraînement
train_texts_preprocessed = [preprocess_text(text) for text in train_ds['review']]

# Afficher quelques exemples de texte prétraité
for i in range(5):
    print("Texte original :", train_ds['review'][i])
    print("Texte prétraité :", train_texts_preprocessed[i])
    print()

# Sélectionner 20% des données de manière aléatoire
train_df_sampled = train_df.sample(frac=0.2, random_state=42)

# Afficher les premières lignes du DataFrame échantillonné
print(train_df_sampled.head())

# Séparer les textes et les étiquettes
train_texts = train_df_sampled['review']
train_labels = train_df_sampled['label']

import re
import string
import nltk
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize
from nltk.stem import WordNetLemmatizer
from datasets import load_dataset
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score

# Téléchargement des ressources NLTK
nltk.download('punkt')
nltk.download('wordnet')
nltk.download('stopwords')

# Prétraitement du texte
def preprocess_text(text):
    text = text.lower()  # Convertir en minuscules
    text = text.translate(str.maketrans('', '', string.punctuation))  # Supprimer la ponctuation
    text = re.sub(r'\d+', '', text)  # Supprimer les chiffres
    tokens = word_tokenize(text)  # Tokenization
    stop_words = set(stopwords.words('french'))  # Charger les stopwords
    filtered_tokens = [word for word in tokens if word not in stop_words]  # Supprimer les stopwords
    lemmatizer = WordNetLemmatizer()  # Initialiser le lemmatizer
    lemmatized_tokens = [lemmatizer.lemmatize(word) for word in filtered_tokens]  # Lemmatisation
    preprocessed_text = ' '.join(lemmatized_tokens)  # Joindre les tokens
    return preprocessed_text

# Charger les données
train_ds, _, _ = load_dataset('allocine', split=['train', 'validation', 'test'])

# Convertir le jeu de données d'entraînement en DataFrame pandas
train_df = train_ds.to_pandas()

# Sélectionner 20% des données de manière aléatoire
train_df_sampled = train_df.sample(frac=0.2, random_state=42)

# Prétraiter chaque texte dans l'ensemble de données d'entraînement
train_df_sampled['review'] = train_df_sampled['review'].apply(preprocess_text)

# Séparer les textes et les étiquettes
train_texts = train_df_sampled['review']
train_labels = train_df_sampled['label']

# Vectorisation des données avec Bag-of-Words
vectorizer_bow = CountVectorizer()
train_features_bow = vectorizer_bow.fit_transform(train_texts)

# Vectorisation des données avec TF-IDF
vectorizer_tfidf = TfidfVectorizer()
train_features_tfidf = vectorizer_tfidf.fit_transform(train_texts)

# Diviser les données échantillonnées en train/validation
train_texts_sampled, val_texts, train_labels_sampled, val_labels = train_test_split(train_texts, train_labels, test_size=0.2, random_state=42)
train_features_bow_sampled, val_features_bow_sampled = train_test_split(train_features_bow, test_size=0.2, random_state=42)
train_features_tfidf_sampled, val_features_tfidf_sampled = train_test_split(train_features_tfidf, test_size=0.2, random_state=42)

# Entraîner et évaluer Logistic Regression avec Bag-of-Words sur les données échantillonnées
lr_bow_sampled = LogisticRegression()
lr_bow_sampled.fit(train_features_bow_sampled, train_labels_sampled)
val_pred_lr_bow_sampled = lr_bow_sampled.predict(val_features_bow_sampled)
accuracy_lr_bow_sampled = accuracy_score(val_labels, val_pred_lr_bow_sampled)
print("Accuracy of Logistic Regression with Bag-of-Words (20% sampled data):", accuracy_lr_bow_sampled)

# Entraîner et évaluer Logistic Regression avec TF-IDF sur les données échantillonnées
lr_tfidf_sampled = LogisticRegression()
lr_tfidf_sampled.fit(train_features_tfidf_sampled, train_labels_sampled)
val_pred_lr_tfidf_sampled = lr_tfidf_sampled.predict(val_features_tfidf_sampled)
accuracy_lr_tfidf_sampled = accuracy_score(val_labels, val_pred_lr_tfidf_sampled)
print("Accuracy of Logistic Regression with TF-IDF (20% sampled data):", accuracy_lr_tfidf_sampled)

from sklearn.svm import SVC
# Entraîner et évaluer SVM avec Bag-of-Words sur les données échantillonnées
svm_bow_sampled = SVC()
svm_bow_sampled.fit(train_features_bow_sampled, train_labels_sampled)
val_pred_svm_bow_sampled = svm_bow_sampled.predict(val_features_bow_sampled)
accuracy_svm_bow_sampled = accuracy_score(val_labels, val_pred_svm_bow_sampled)
print("Accuracy of SVM with Bag-of-Words (20% sampled data):", accuracy_svm_bow_sampled)

from sklearn.svm import SVC

# Diviser les données en train/validation en utilisant seulement 20% des données
#train_features_bow_sampled, val_features_bow_sampled, train_labels_sampled, val_labels_sampled = train_test_split(train_features_bow, train_labels, test_size=0.2, random_state=42)

# Entraîner et évaluer SVM avec Bag-of-Words sur les données échantillonnées
svm_bow_sampled = SVC()
svm_bow_sampled.fit(train_features_bow_sampled, train_labels_sampled)
val_pred_svm_bow_sampled = svm_bow_sampled.predict(val_features_bow_sampled)
accuracy_svm_bow_sampled = accuracy_score(val_labels_sampled, val_pred_svm_bow_sampled)
print("Accuracy of SVM with Bag-of-Words (20% sampled data):", accuracy_svm_bow_sampled)

import numpy as np
import tensorflow as tf
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Embedding, SpatialDropout1D
from sklearn.metrics import accuracy_score
from sklearn.model_selection import train_test_split
from datasets import load_dataset

# Charger les données
train_ds, val_ds, test_ds = load_dataset('allocine', split=['train', 'validation', 'test'])

# Sélectionner 20% des données de manière aléatoire
train_texts_sampled, _, train_labels_sampled, _ = train_test_split(train_ds['review'], train_ds['label'], test_size=0.2, random_state=42)

# Diviser les données échantillonnées en train et test
train_texts, test_texts, train_labels, test_labels = train_test_split(train_texts_sampled, train_labels_sampled, test_size=0.2, random_state=42)

# Tokenization et padding
max_len = 100  # Longueur maximale des séquences
tokenizer = tf.keras.preprocessing.text.Tokenizer()
tokenizer.fit_on_texts(train_texts)
train_sequences = tokenizer.texts_to_sequences(train_texts)
train_padded = pad_sequences(train_sequences, maxlen=max_len, padding='post', truncating='post')
test_sequences = tokenizer.texts_to_sequences(test_texts)
test_padded = pad_sequences(test_sequences, maxlen=max_len, padding='post', truncating='post')

# Convertir les étiquettes en tableaux Numpy
train_labels = np.array(train_labels)
test_labels = np.array(test_labels)

# Création du modèle LSTM
embedding_dim = 100
model = Sequential([
    Embedding(len(tokenizer.word_index) + 1, embedding_dim, input_length=max_len),
    SpatialDropout1D(0.2),
    LSTM(100, dropout=0.2, recurrent_dropout=0.2),
    Dense(1, activation='sigmoid')
])

# Compilation du modèle
model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])

# Entraînement du modèle
epochs = 5
batch_size = 64
history = model.fit(train_padded, train_labels, epochs=epochs, batch_size=batch_size, validation_split=0.2, verbose=2)

# Évaluation du modèle sur l'ensemble de test
test_loss, test_accuracy = model.evaluate(test_padded, test_labels, verbose=0)
print("Accuracy on test set:", test_accuracy)

# Prédiction sur l'ensemble de test
test_predictions = (model.predict(test_padded) > 0.5).astype("int32")
print("Accuracy score on test set:", accuracy_score(test_labels, test_predictions))





from tensorflow.keras.optimizers import RMSprop, SGD

# Création du modèle LSTM avec l'optimiseur RMSprop
model_rmsprop = Sequential([
    Embedding(len(tokenizer.word_index) + 1, embedding_dim, input_length=max_len),
    SpatialDropout1D(0.2),
    LSTM(100, dropout=0.2, recurrent_dropout=0.2),
    Dense(1, activation='sigmoid')
])
model_rmsprop.compile(loss='binary_crossentropy', optimizer=RMSprop(), metrics=['accuracy'])

# Entraînement du modèle avec l'optimiseur RMSprop
model_rmsprop.fit(train_padded, train_labels, epochs=5, batch_size=64, validation_data=(val_padded, val_labels), verbose=2)

# Création du modèle LSTM avec l'optimiseur SGD
model_sgd = Sequential([
    Embedding(len(tokenizer.word_index) + 1, embedding_dim, input_length=max_len),
    SpatialDropout1D(0.2),
    LSTM(100, dropout=0.2, recurrent_dropout=0.2),
    Dense(1, activation='sigmoid')
])
model_sgd.compile(loss='binary_crossentropy', optimizer=SGD(), metrics=['accuracy'])

# Entraînement du modèle avec l'optimiseur SGD
model_sgd.fit(train_padded, train_labels, epochs=5, batch_size=64, validation_data=(val_padded, val_labels), verbose=2)

# Évaluation des modèles sur l'ensemble de test
test_loss_rmsprop, test_accuracy_rmsprop = model_rmsprop.evaluate(test_padded, test_labels, verbose=0)
print("Accuracy on test set with RMSprop optimizer:", test_accuracy_rmsprop)

test_loss_sgd, test_accuracy_sgd = model_sgd.evaluate(test_padded, test_labels, verbose=0)
print("Accuracy on test set with SGD optimizer:", test_accuracy_sgd)

from sklearn.metrics import confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt

# Prédiction des étiquettes sur l'ensemble de test pour les trois modèles
test_predictions_adam = (model.predict(test_padded) > 0.5).astype("int32")

# Calcul des matrices de confusion pour chaque modèle
conf_matrix_adam = confusion_matrix(test_labels, test_predictions_adam)

# Affichage des matrices de confusion pour chaque modèle
plt.figure(figsize=(18, 6))

plt.subplot(1, 3, 1)
sns.heatmap(conf_matrix_rmsprop, annot=True, fmt="d", cmap="Blues", cbar=False)
plt.title("Confusion Matrix (RMSprop)")
plt.xlabel("Predicted Label")
plt.ylabel("True Label")

plt.subplot(1, 3, 2)
sns.heatmap(conf_matrix_sgd, annot=True, fmt="d", cmap="Blues", cbar=False)
plt.title("Confusion Matrix (SGD)")
plt.xlabel("Predicted Label")
plt.ylabel("True Label")

plt.subplot(1, 3, 3)
sns.heatmap(conf_matrix_adam, annot=True, fmt="d", cmap="Blues", cbar=False)
plt.title("Confusion Matrix (Adam)")
plt.xlabel("Predicted Label")
plt.ylabel("True Label")

plt.tight_layout()
plt.show()

"""Examiner les faux positifs et les faux négatifs : Identifiez les exemples où le modèle a prédit à tort une classe positive (faux positifs) ou une classe négative (faux négatifs). Examinez le texte associé à ces exemples pour comprendre pourquoi le modèle s'est trompé.

**Analyser les motifs communs** : Recherchez des motifs ou des thèmes communs dans les exemples mal classés. Il peut y avoir des motifs spécifiques dans le texte qui induisent le modèle en erreur.

**Vérifier les prédictions ambiguës** : Parfois, les exemples peuvent être ambigus même pour un humain. Vérifiez si les exemples mal classés sont ambigus ou contiennent des informations contradictoires.

**Explorer les différences entre les classes** : Comparez les caractéristiques des exemples de différentes classes pour voir s'il y a des différences significatives qui pourraient expliquer les erreurs du modèle.

**Considérer la qualité des données** : Assurez-vous que les exemples mal classés ne sont pas le résultat de données mal étiquetées ou bruyantes. Parfois, des erreurs dans les étiquetages peuvent entraîner des erreurs de modèle.
"""

